{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üç´ Creative common license dataset\n",
    "\n",
    "\n",
    "This sample pipeline demonstrates how to effectively utilize a creative\n",
    "commons image dataset within a fondant pipeline. This dataset comprises images from diverse sources and is available in various data formats.\n",
    "[The dataset](https://huggingface.co/datasets/fondant-ai/fondant-cc-25m) itself is available on Huggingface.\n",
    "\n",
    "\n",
    "\n",
    "### Pipeline overview\n",
    "\n",
    "The primary goal of this sample is to showcase how you can use a Fondant pipeline and reusable\n",
    "components to load an image dataset from HuggingFace Hub and download all images.\n",
    "Pipeline Steps:\n",
    "\n",
    "- [Load from Huggingface Hub](https://github.com/ml6team/fondant/tree/main/components/load_from_hf_hub):\n",
    "  The pipeline begins by loading the image dataset from Huggingface Hub.\n",
    "- [Download Images](https://github.com/ml6team/fondant/tree/main/components/download_images): \n",
    "  The download image component download images and stores them to parquet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup your environment \n",
    "!pip install \"fondant[docker]==0.6.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the pipeline\n",
    "\n",
    "First of all, we need to initialize the pipeline, which includes specifying a name for your pipeline, providing a description, and setting a base_path. The base_path is used to store the pipeline artifacts and data generated by the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pipeline.py\n",
    "from fondant.pipeline import ComponentOp, Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    pipeline_name=\"filter-creative-commons\",  # Add a unique pipeline name to easily track your progress and data\n",
    "    pipeline_description=\"Load cc image dataset\",\n",
    "    base_path=\"./data-dir\", # The demo pipelines uses a local directory to store the data.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will utilize a dataset available on HuggingFace. As such, we will use a reusable Fondant component `load_from_hf_hub`. The `load_from_hf_hub` component is a generic one, which implies that we still need to customize the component specification file. We have to modify the dataframe schema defined in the produce section of the component.\n",
    "\n",
    "To achieve this, we can create a `fondant_component.yaml` file in the directory `components/load_from_hf_hub` with the following content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile components/load_from_hf_hub/fondant_component.yaml\n",
    "name: Load from hub\n",
    "description: Component that loads a dataset from the hub\n",
    "image: fndnt/load_from_hf_hub:0.6.2\n",
    "\n",
    "produces:\n",
    "  images:\n",
    "    fields:\n",
    "      alt+text:\n",
    "        type: string\n",
    "      url:\n",
    "        type: string\n",
    "      license+location:\n",
    "        type: string\n",
    "      license+type:\n",
    "        type: string\n",
    "      webpage+url:\n",
    "        type: string\n",
    "      surt+url:\n",
    "        type: string\n",
    "      top+level+domain:\n",
    "        type: string\n",
    "\n",
    "args:\n",
    "  dataset_name:\n",
    "    description: Name of dataset on the hub\n",
    "    type: str\n",
    "  column_name_mapping:\n",
    "    description: Mapping of the consumed hub dataset to fondant column names\n",
    "    type: dict\n",
    "    default: {}\n",
    "  image_column_names:\n",
    "    description: Optional argument, a list containing the original image column names in case the \n",
    "      dataset on the hub contains them. Used to format the image from HF hub format to a byte string.\n",
    "    type: list\n",
    "    default: []\n",
    "  n_rows_to_load:\n",
    "    description: Optional argument that defines the number of rows to load. Useful for testing pipeline runs on a small scale\n",
    "    type: int\n",
    "  index_column:\n",
    "    description: Column to set index to in the load component, if not specified a default globally unique index will be set\n",
    "    type: str\n",
    "    default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we can initialize the component and add it to our pipeline.\n",
    "It's important to note that we are using the `load_component_column_mapping` to define which columns of the Huggingface dataset will be mapped to the schema of the dataset that Fondant operates on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a pipeline.py\n",
    "# Load from hub component\n",
    "load_component_column_mapping = {\n",
    "    \"alt_text\": \"images_alt+text\",\n",
    "    \"image_url\": \"images_url\",\n",
    "    \"license_location\": \"images_license+location\",\n",
    "    \"license_type\": \"images_license+type\",\n",
    "    \"webpage_url\": \"images_webpage+url\",\n",
    "    \"surt_url\": \"images_surt+url\",\n",
    "    \"top_level_domain\": \"images_top+level+domain\",\n",
    "}\n",
    "\n",
    "load_from_hf_hub = ComponentOp(\n",
    "    component_dir=\"components/load_from_hf_hub\",\n",
    "    arguments={\n",
    "        \"dataset_name\": \"fondant-ai/fondant-cc-25m\",\n",
    "        \"column_name_mapping\": load_component_column_mapping,\n",
    "        \"n_rows_to_load\": 100,  # Here you can modify the number of images you want to download.\n",
    "    }\n",
    ")\n",
    "\n",
    "pipeline.add_op(load_from_hf_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, our pipeline comprises a single component responsible for loading the dataset from the HuggingFace Hub. We have the flexibility to include additional components in the pipeline. In this instance, our objective is to download all the images. For this purpose, we will employ a reusable component named `download_images`. To make use of a reusable component, we can utilize the `ComponentOp.from_registry(...)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a pipeline.py\n",
    "download_images = ComponentOp.from_registry(\n",
    "    name=\"download_images\",\n",
    "    arguments={\"input_partition_rows\": 100, \"resize_mode\": \"no\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reusable components offer various arguments that typically affect the component's operations. In this case, we have set, for example, `\"resize_mode\": \"no\"`. This setting ensures that the images will not be resized after they are downloaded. If you would like to learn more about components and their arguments, please refer to our [documentation](https://fondant.ai) and explore the [ComponentHub](https://hub.fondant.ai).\n",
    "\n",
    "\n",
    "Now, we can use the components in our pipeline. It is important to note that we will define dependencies between the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a pipeline.py\n",
    "pipeline.add_op(download_images, dependencies=[load_from_hf_hub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the pipeline\n",
    "\n",
    "Now we are ready to execute our pipeline. \n",
    "Fondant provides various executors, and in this case, we are using the LocalRunner, which utilizes Docker under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fondant run local pipeline.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
